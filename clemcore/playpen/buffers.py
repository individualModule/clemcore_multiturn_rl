from typing import List, Dict
import random
import warnings
import pickle
import torch

from clemcore.clemgame import Player
from clemcore.playpen.envs.game_env import GameEnv
from clemcore.playpen.envs.branching_env import GameBranchingEnv


class RolloutBuffer:

    def __init__(self, game_env):
        self.game_env = game_env
        self.initial_prompts: Dict[Player, Dict] = {}  # initial prompts that are not given in the initial context

    def on_step(self, context, response, done, info):
        pass

    def on_done(self):
        pass

    def reset(self):
        pass

    def get_perspective_of(self, player: Player):
        pass  # todo


class StepRolloutBuffer(RolloutBuffer):
    """ This buffer can collect the trajectories generated by a game env """

    def __init__(self, game_env: GameEnv):
        assert isinstance(game_env, GameEnv), "StepRolloutBuffer can only be used with GameEnv"
        super().__init__(game_env)
        self.trajectories: List = None
        self.current_trajectory: int = None
        self.reset()

    def on_step(self, context, response, done, info):
        step = dict(context=context, response=response, done=done, info=info)
        self.trajectories[self.current_trajectory].append(step)

    def on_done(self):
        self.trajectories.append([])
        self.current_trajectory += 1

    def reset(self):
        self.trajectories = [[]]
        self.current_trajectory = 0

    def sample_trajectories(self):
        return self.trajectories
    
    def drop_trajectory(self):
        self.trajectories[-1] = []

class BranchingRolloutBuffer(RolloutBuffer):
    """ This buffer can collect the trajectories generated by the branching env """

    def __init__(self, game_env: GameBranchingEnv):
        assert isinstance(game_env, GameBranchingEnv), "TreeRolloutBuffer can only be used with GameBranchingEnv"
        super().__init__(game_env)
        self.forest: List = None
        self.reset()

    def on_done(self):
        active_tree = self.game_env.get_active_tree()
        self.forest.append(active_tree)

    def reset(self):
        self.forest = []

class ReplayBuffer(StepRolloutBuffer):
    """
    Replay buffer with a fixed size that removes the oldest samples when full
    """

    def __init__(self, game_env: GameEnv, buffer_size: int, sample_size: int):
        """
        buffer size defines trajectories currently. Should it define steps/
        """
        super().__init__(game_env)
        self.buffer_size = buffer_size
        self.sample_size = sample_size
        self.steps: List[dict] = [] # flattened steps needed to sample steps.


    def on_done(self):
        """Add the current trajectory to the buffer and enforce buffer size."""
        super().on_done()
        # Remove the oldest trajectories if the buffer exceeds its size
        excess_count = len(self.trajectories) - self.buffer_size
        if excess_count > 0:
            self.trajectories = self.trajectories[excess_count:]  # Keep only the most recent trajectories
            self.current_trajectory -= excess_count

        if self.current_trajectory < 0:
            self.current_trajectory = 0


    def sample(self, sample_size: int):
        """Randomly sample trajectories from the buffer."""
        if len(self.trajectories) < sample_size:
            warnings.warn(
                f"Requested sample size ({sample_size}) is larger than the number of stored trajectories "
                f"({len(self.trajectories)}). Returning all available trajectories."
            )
            return self.trajectories[:-1]
        return random.sample(self.trajectories[:-1], sample_size)

    def sample_trajectories(self):
        """Return a random sample of trajectories."""
        return self.sample(self.sample_size)
    
    def flatten_steps(self):
        """
        Flatten trajectories into individual steps.
        needed to match ArCHer sampling - where random steps are sampled, not trajectories.

        Only do it after rollouts are done - so once per iteration.
        """
        self.steps = []
        for trajectory in self.trajectories:
            for i in range(len(trajectory)):
                current = trajectory[i]
                next_step = trajectory[i + 1] if i + 1 < len(trajectory) else None
                self.steps.append({
                    'obs': current['context'],
                    'action': current['response'],
                    'reward': torch.tensor(
                        current['info']['response_score'] if next_step else current['info']['episode_score'],
                        dtype=torch.float
                    ),
                    'next_obs': next_step['context'] if next_step else current['context'],
                    'done': torch.tensor(current['done'], dtype=torch.bool)
                })

    def sample_steps(self):
        """Randomly sample individual steps from the buffer."""
        if len(self.steps) < self.sample_size:
            warnings.warn(
                f"Requested sample size ({self.sample_size}) is larger than the number of stored steps "
                f"({len(self.steps)}). Returning all available steps."
            )
            return self.steps
        return random.sample(self.steps, self.sample_size)

    def save_buffer(self, file_path: str, default_name = True):
        """Save the buffer (trajectories and current trajectory) to a file using pickle."""
        # Append a default file name to the provided file path
        if default_name:
            file_path += "_replay_buffer.pkl"
        
        data = {
            "trajectories": self.trajectories,
            "current_trajectory": self.current_trajectory
        }

        with open(file_path, "wb") as f:
            pickle.dump(data, f)
        print(f"Buffer saved to {file_path}")

    def load_buffer(self, file_path: str):
        """Load the buffer (trajectories and current trajectory) from a file."""
        
        with open(file_path, "rb") as f:
            data = pickle.load(f)
        self.trajectories = data["trajectories"]
        self.current_trajectory = data["current_trajectory"]
        print(f"Buffer loaded from {file_path}")